owner,started_at,framework,benchmark,dataset,task,model_name,score,score_name,all_scores,run_params
ilab,2024-08-15 10:04:20.387117,Unitxt,ilab,rag.response_generation.clapnq,rag,models/merlinite-7b-lab-Q4_K_M.gguf,0.29938358286124384,f1,"{'f1': np.float64(0.29938358286124384), 'score': np.float64(0.29938358286124384), 'precision': np.float64(0.2541600093017585), 'recall': np.float64(0.7161510317009189), 'recall_ci_low': np.float64(0.6694286862991615), 'recall_ci_high': np.float64(0.7584161675855544), 'f1_ci_low': np.float64(0.26175729701851896), 'f1_ci_high': np.float64(0.34210379770679933), 'score_ci_low': np.float64(0.26175729701851896), 'score_ci_high': np.float64(0.34210379770679933), 'precision_ci_low': np.float64(0.21070524424409723), 'precision_ci_high': np.float64(0.30641232461164103), 'correctness_f1_bert_score.deberta_large_mnli': 0.5709355428814888, 'correctness_recall_bert_score.deberta_large_mnli': 0.7020367294549942, 'correctness_precision_bert_score.deberta_large_mnli': 0.4993984484672546, 'faithfullness_f1_token_overlap': np.float64(0.39478111123334897), 'faithfullness_recall_token_overlap': np.float64(0.5184865415246093), 'faithfullness_precision_token_overlap': np.float64(0.48031660891212913), 'correctness_f1_token_overlap': np.float64(0.29938358286124384), 'correctness_recall_token_overlap': np.float64(0.7161510317009189), 'correctness_precision_token_overlap': np.float64(0.2541600093017585)}","{'loader_limit': '100', 'host': 'cccxc421', 'folder': 'instructlab', 'num_shots': 5}"
