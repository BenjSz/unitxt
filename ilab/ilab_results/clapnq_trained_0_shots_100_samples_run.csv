owner,started_at,framework,benchmark,dataset,task,model_name,score,score_name,all_scores,run_params
ilab,2024-08-15 09:23:56.806181,Unitxt,ilab,rag.response_generation.clapnq,rag,models/merlinite-7b-lab-Q4_K_M.gguf,0.41315759245811035,f1,"{'f1': np.float64(0.41315759245811035), 'score': np.float64(0.41315759245811035), 'precision': np.float64(0.5564639550868139), 'recall': np.float64(0.44296533138377037), 'recall_ci_low': np.float64(0.3944754756689709), 'recall_ci_high': np.float64(0.4960782360865947), 'f1_ci_low': np.float64(0.37392050557295425), 'f1_ci_high': np.float64(0.45386838695317816), 'score_ci_low': np.float64(0.37392050557295425), 'score_ci_high': np.float64(0.45386838695317816), 'precision_ci_low': np.float64(0.501895065970238), 'precision_ci_high': np.float64(0.6167594498295218), 'correctness_f1_bert_score.deberta_large_mnli': 0.6437757024168969, 'correctness_recall_bert_score.deberta_large_mnli': 0.6251482598483562, 'correctness_precision_bert_score.deberta_large_mnli': 0.6857575100660324, 'faithfullness_f1_token_overlap': np.float64(0.3003338014075434), 'faithfullness_recall_token_overlap': np.float64(0.2271068503959992), 'faithfullness_precision_token_overlap': np.float64(0.7409047854821036), 'correctness_f1_token_overlap': np.float64(0.41315759245811035), 'correctness_recall_token_overlap': np.float64(0.44296533138377037), 'correctness_precision_token_overlap': np.float64(0.5564639550868139)}","{'loader_limit': '100', 'host': 'cccxc421', 'folder': 'instructlab', 'num_shots': 0}"
